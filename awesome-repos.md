- https://github.com/simonw/llm

<img width="734" alt="Screenshot 2023-11-30 at 12 32 12 PM" src="https://github.com/andysingal/modern_nlp_2/assets/20493493/7bb17e51-6c1c-4f72-8b3f-608120b0d362">

https://blog.ouseful.info/2023/11/29/looking-up-ipython-local-llm-ai-magic-promt-history/

<img width="921" alt="Screenshot 2023-11-30 at 12 39 11 PM" src="https://github.com/andysingal/modern_nlp_2/assets/20493493/5bb509be-cf7d-4119-bfe5-1066c9ca4832">


- https://github.com/BlackHC/llm-strategy/tree/main

- Simple and efficient pytorch-native transformer text generation. https://github.com/pytorch-labs/gpt-fast

- GitHub to Hugging Face Hub Dataset Migration Tool https://huggingface.co/spaces/librarian-bots/github-to-huggingface-dataset-migration-tool

- Love to code on your Mac machine, please check : https://github.com/ml-explore/mlx-examples 
<img width="834" alt="Screenshot 2023-12-20 at 7 38 37 AM" src="https://github.com/andysingal/modern_nlp_2/assets/20493493/5af16a5f-b4ef-4fde-9251-0a3018e806fe">

Pro Prompter idea https://makereal.tldraw.com/ 
<img width="1617" alt="Screenshot 2023-12-20 at 7 46 44 AM" src="https://github.com/andysingal/modern_nlp_2/assets/20493493/de3a8950-1d30-4f2c-868b-3a8526df0f6d">

nanoGPT: The simplest, fastest repository for training/finetuning medium-sized GPTs. It is a rewrite of minGPT that prioritizes teeth over education. Still under active development, but currently the file train.py reproduces GPT-2 (124M) on OpenWebText, running on a single 8XA100 40GB node in about 4 days of training. The code itself is plain and readable: train.py is a ~300-line boilerplate training loop and model.py a ~300-line GPT model definition, which can optionally load the GPT-2 weights from OpenAI. That's it.
https://github.com/karpathy/nanoGPT



Invoice data processing LLM RAG on CPU with Ollama  https://github.com/katanaml/llm-ollama-llamaindex-invoice-cpu

Panel Tweak Matplotlib: https://huggingface.co/spaces/ahuang11/tweak-mpl-chat 

Rank llm: https://github.com/castorini/rank_llm

link: https://a16z.com/ai-canon/ 

Quantize Mixtral-8x7B so it can run in 24GB GPU : https://github.com/casper-hansen/AutoAWQ 

NL-FM-Toolkit https://ibm.github.io/NL-FM-Toolkit/_modules/run_tc.html 

Invoice Extractor: Ollama: https://github.com/katanaml/llm-ollama-llamaindex-invoice-cpu

optimum-deepsparse : https://pypi.org/project/optimum-deepsparse/

Mamba Multimodel: https://github.com/kyegomez/MultiModalMamba/tree/main 

DragNUWA https://huggingface.co/spaces/yinsming/DragNUWA

GPTEval3D - https://github.com/3DTopia/GPTEval3D 

Ollama-Chat: https://github.com/mckaywrigley/chatbot-ui 

neural-compressor: https://github.com/intel/neural-compressor 

Renumics/spotlight - https://github.com/Renumics/spotlight 

<img width="894" alt="Screenshot 2024-01-12 at 7 33 59 PM" src="https://github.com/andysingal/llm-course/assets/20493493/2216b77d-bd77-4b95-bd89-18602584e10e">
