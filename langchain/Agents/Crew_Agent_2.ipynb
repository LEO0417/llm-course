{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z25_W-Bg5wk",
        "outputId": "b4a29e51-fe29-4132-c6a8-4e989dd92df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.7/521.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.7/187.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.0/334.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install crewai langchain-community langchain-openai requests duckduckgo-search chromadb -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.tools import tool\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import requests, os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "OPENAI_API_KEY=\"\"\n",
        "\n",
        "embedding_function = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\",openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Tool 1 : Save the news articles in a database\n",
        "class SearchNewsDB:\n",
        "    @tool(\"News DB Tool\")\n",
        "    def news(query: str):\n",
        "        \"\"\"Fetches news articles and processes their contents.\"\"\"\n",
        "\n",
        "        articles = [\n",
        "            \"https://www.bbc.com/news/world-us-canada-66388172\",\n",
        "            \"https://www.bbc.com/news/entertainment-arts-66384971\",\n",
        "        ]\n",
        "        all_splits = []\n",
        "        for article in articles:\n",
        "            # Assuming WebBaseLoader can handle a list of URLs\n",
        "            loader = WebBaseLoader(article['url'])\n",
        "            docs = loader.load()\n",
        "\n",
        "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "            splits = text_splitter.split_documents(docs)\n",
        "            all_splits.extend(splits)  # Accumulate splits from all articles\n",
        "\n",
        "        # Index the accumulated content splits if there are any\n",
        "        if all_splits:\n",
        "            vectorstore = Chroma.from_documents(all_splits, embedding=embedding_function, persist_directory=\"./chroma_db\")\n",
        "            retriever = vectorstore.similarity_search(query)\n",
        "            return retriever\n",
        "        else:\n",
        "            return \"No content available for processing.\"\n",
        "# Tool 2 : Get the news articles from the database\n",
        "class GetNews:\n",
        "    @tool(\"Get News Tool\")\n",
        "    def news(query: str) -> str:\n",
        "        \"\"\"Search Chroma DB for relevant news information based on a query.\"\"\"\n",
        "        vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)\n",
        "        retriever = vectorstore.similarity_search(query)\n",
        "        return retriever\n",
        "\n",
        "# Tool 3 : Search for news articles on the web\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "\n",
        "# 2. Creating Agents\n",
        "news_search_agent = Agent(\n",
        "    role='News Seacher',\n",
        "    goal='Generate key points for each news article from the latest news',\n",
        "    backstory='Expert in analysing and generating key points from news content for quick updates.',\n",
        "    tools=[SearchNewsDB().news],\n",
        "    allow_delegation=True,\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "writer_agent = Agent(\n",
        "    role='Writer',\n",
        "    goal='Identify all the topics received. Use the Get News Tool to verify the each topic to search. Use the Search tool for detailed exploration of each topic. Summarise the retrieved information in depth for every topic.',\n",
        "    backstory='Expert in crafting engaging narratives from complex information.',\n",
        "    tools=[GetNews().news, search_tool],\n",
        "    allow_delegation=True,\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# 3. Creating Tasks\n",
        "news_search_task = Task(\n",
        "    description='Search for AI 2024 and create key points for each news.',\n",
        "    agent=news_search_agent,\n",
        "    tools=[SearchNewsDB().news]\n",
        ")\n",
        "\n",
        "writer_task = Task(\n",
        "    description=\"\"\"\n",
        "    Go step by step.\n",
        "    Step 1: Identify all the topics received.\n",
        "    Step 2: Use the Get News Tool to verify the each topic by going through one by one.\n",
        "    Step 3: Use the Search tool to search for information on each topic one by one.\n",
        "    Step 4: Go through every topic and write an in-depth summary of the information retrieved.\n",
        "    Don't skip any topic.\n",
        "    \"\"\",\n",
        "    agent=writer_agent,\n",
        "    context=[news_search_task],\n",
        "    tools=[GetNews().news, search_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "Wg62Nu2ShCbf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Creating Crew\n",
        "news_crew = Crew(\n",
        "    agents=[news_search_agent, writer_agent],\n",
        "    tasks=[news_search_task, writer_task],\n",
        "    process=Process.sequential,\n",
        "    manager_llm=llm\n",
        ")\n",
        "\n",
        "# Execute the crew to see RAG in action\n",
        "result = news_crew.kickoff()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOz0SJhIiqKI",
        "outputId": "61384118-66c2-4db4-f011-3096ce8e5816"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```\n",
            "Use Tool: News DB Tool(query: \"AI 2024\")\n",
            "```\n",
            "\u001b[0m\u001b[91m \n",
            "\n",
            "It seems we encountered an unexpected error while trying to use the tool. This was the error: string indices must be integers\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: Due to an unexpected error encountered while attempting to use the News DB Tool with the query \"AI 2024\", I am unable to provide key points from the latest news articles related to AI in 2024. I apologize for the inconvenience and recommend trying the query again later or consulting a different source for the latest updates on AI in 2024.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mUse Tool: Get News Tool(query: \"AI 2024\")\u001b[0m\u001b[93m \n",
            "\n",
            "[]\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mUse Tool: duckduckgo_search(query: \"AI 2024\")\u001b[0m\u001b[93m \n",
            "\n",
            "The web page predicts four hot topics in artificial intelligence for the next year, such as customized chatbots, generative video, AI-generated election disinformation, and AI-powered robots. It also reviews the performance of its predictions for 2023 and the challenges and opportunities of AI in various domains. 10 AI Predictions For 2024 Rob Toews Contributor I write about the big picture of artificial intelligence. Click to save this article. You'll be asked to sign into your Forbes account. Got it... The Top 5 Artificial Intelligence (AI) Trends For 2024 Adobe Stock It's been a year since OpenAI released ChatGPT, opening the door to seamlessly weave AI into the fabric of our daily lives,... Seven experts from Stanford's Human-Centered AI Institute share their insights on the future of artificial intelligence, including generative models, deepfakes, regulation, and more. Read their predictions and learn how AI will affect white collar work, multimedia, and society. Gregory C. Allen: Yeah, so 2024 has almost every democracy on earth, just coincidentally has an election in 2024. The stars have aligned, the calendars have aligned, and so there's so many elections in 2024 and now AI is going to be a factor in two ways. Number one, I think AI is going to be part of the machinery of campaigning and running ...\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: Based on the information retrieved from the DuckDuckGo search regarding \"AI 2024,\" the following key topics and insights have been identified:\n",
            "\n",
            "1. **Customized Chatbots**: The evolution of chatbots into highly personalized assistants is anticipated. These advanced chatbots are expected to offer more tailored interactions and services, enhancing user experience across various platforms and industries.\n",
            "\n",
            "2. **Generative Video**: AI's role in video production is predicted to expand significantly. Generative video technology, powered by AI, could enable the creation of more sophisticated and realistic video content, possibly altering how we produce and consume digital media.\n",
            "\n",
            "3. **AI-Generated Election Disinformation**: A concerning prediction is the potential use of AI in spreading disinformation during elections. With 2024 being a year where many democracies around the world will hold elections, the misuse of AI to generate and disseminate false information could pose significant challenges to electoral integrity.\n",
            "\n",
            "4. **AI-Powered Robots**: The development and deployment of more advanced AI-powered robots are expected. These robots could take on more complex tasks and roles, potentially transforming various sectors including manufacturing, healthcare, and service industries.\n",
            "\n",
            "5. **AI Trends and Insights**: The search results also highlight a review of past predictions for AI in 2023, discussing the challenges and opportunities AI presents in various domains. Insights from seven experts from Stanford's Human-Centered AI Institute were mentioned, covering topics such as generative models, deepfakes, regulation, and the broader impact of AI on white-collar work, multimedia, and society.\n",
            "\n",
            "These topics suggest that 2024 will be a significant year for AI, with advancements that could profoundly influence how we interact with technology, the authenticity and integrity of information, and the automation of tasks across industries. The potential for AI to impact elections through disinformation campaigns also raises important ethical and regulatory considerations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Based on the information retrieved from the DuckDuckGo search regarding \"AI 2024,\" the following key topics and insights have been identified:\n",
            "\n",
            "1. **Customized Chatbots**: The evolution of chatbots into highly personalized assistants is anticipated. These advanced chatbots are expected to offer more tailored interactions and services, enhancing user experience across various platforms and industries.\n",
            "\n",
            "2. **Generative Video**: AI's role in video production is predicted to expand significantly. Generative video technology, powered by AI, could enable the creation of more sophisticated and realistic video content, possibly altering how we produce and consume digital media.\n",
            "\n",
            "3. **AI-Generated Election Disinformation**: A concerning prediction is the potential use of AI in spreading disinformation during elections. With 2024 being a year where many democracies around the world will hold elections, the misuse of AI to generate and disseminate false information could pose significant challenges to electoral integrity.\n",
            "\n",
            "4. **AI-Powered Robots**: The development and deployment of more advanced AI-powered robots are expected. These robots could take on more complex tasks and roles, potentially transforming various sectors including manufacturing, healthcare, and service industries.\n",
            "\n",
            "5. **AI Trends and Insights**: The search results also highlight a review of past predictions for AI in 2023, discussing the challenges and opportunities AI presents in various domains. Insights from seven experts from Stanford's Human-Centered AI Institute were mentioned, covering topics such as generative models, deepfakes, regulation, and the broader impact of AI on white-collar work, multimedia, and society.\n",
            "\n",
            "These topics suggest that 2024 will be a significant year for AI, with advancements that could profoundly influence how we interact with technology, the authenticity and integrity of information, and the automation of tasks across industries. The potential for AI to impact elections through disinformation campaigns also raises important ethical and regulatory considerations.\n"
          ]
        }
      ]
    }
  ]
}