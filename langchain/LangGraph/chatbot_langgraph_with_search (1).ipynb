{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1dXuGpdoqYZ"
      },
      "source": [
        "# Build a more capable LLM powered chatbot using LangGraph and web search tool\n",
        "In this first tutorial of how to use LangGraph, we will build a more capable LLM powered chatbot using LangGraph and web search tool, to find relevant information and provide better responses to users, without being limited to data used for training the llm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV5hO0gJoqYa"
      },
      "source": [
        "# Summary\n",
        "- Installations\n",
        "- Setting environment variables\n",
        "- Importing necessary packages\n",
        "- Creating our chatbot using LangGraph to answer questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8G3GedvoqYa"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h5zJzRQoqYb"
      },
      "outputs": [],
      "source": [
        "pip install -U langgraph langchain_openai langchain-community tavily-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw5bfIYSoqYb"
      },
      "source": [
        "# Set environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4w6wsmtoqYb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNFR1jSUoqYb"
      },
      "source": [
        "# Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi53ZadooqYb"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-xSB0xboqYc"
      },
      "source": [
        "# Define and use tavily search tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHjgftjWoqYc",
        "outputId": "56c3daf4-8401-47fe-d796-08072d7835ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n",
              "  'content': 'NodesÂ¶ In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id). Similar to NetworkX, you add these nodes to a graph using the add_node method:'},\n",
              " {'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48',\n",
              "  'content': 'Each node in a LangGraph graph has the ability to access, read, and write to the state. When a node modifies the state, it effectively broadcasts this information to all other nodes within the graph .'}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "tool.invoke(\"What's a 'node' in LangGraph?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBNUr4wXoqYc"
      },
      "source": [
        "The results are page summaries our chat bot can use to answer questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJQxO9PuoqYc"
      },
      "source": [
        "# Create a `StateGraph`\n",
        "\n",
        "The first thing you do when you define a graph is define the `State` of the graph using the `StateGraph` object.\n",
        "\n",
        "A `StateGraph` object defines the structure of our chatbot as a \"state machine\".\n",
        "\n",
        "The `State` consists of the schema of the graph as well as reducer functions which specify how to apply updates to the state.\n",
        "\n",
        "In our example `State` is a `TypedDict` with a single key: `messages`.\n",
        "\n",
        "The `messages` key is annotated with the `add_messages` reducer function, which tells `LangGraph` to append new messages to the existing list, rather than overwriting it.\n",
        "\n",
        "`State` keys without an annotation will be overwritten by each update, storing the most recent value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKgJytxzoqYc"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5DlqFmKoqYd"
      },
      "source": [
        "So now our graph knows two things:\n",
        "\n",
        "- Every `node` we define will receive the current `State` as input and return a value that updates that state.\n",
        "\n",
        "- `messages` will be appended to the current list, rather than directly overwritten. This is communicated via the prebuilt `add_messages` function in the `Annotated` syntax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQZj09lhoqYd"
      },
      "source": [
        "Next, add a `chatbot` node. Nodes represent units of work. They are typically regular python functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmfBuZ4BoqYd"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LXmN-qPoqYd"
      },
      "source": [
        "Notice how the `chatbot` node function takes the current `State` as input and returns a dictionary containing an updated `messages` list under the key `messages`. This is the basic pattern for all `LangGraph` node functions.\n",
        "\n",
        "The `add_messages` function in our `State` will append the llm's response messages to whatever messages are already in the state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCwUModuoqYd"
      },
      "source": [
        "Next we need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node.\n",
        "\n",
        "In this cell, we implement a BasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM's tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSv-kytjoqYd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UdvnFvroqYd"
      },
      "source": [
        "Now in the next cell we'll use conditional edges using `if` statement, to route to different nodes depending on the current graph state.\n",
        "\n",
        "In our case, the condition either route to `tools` if tool calls are present or to `__end__` if not.\n",
        "When the graph transitions to `__end__`, it has no more tasks to complete and ceases execution.\n",
        "\n",
        "So the function `root_tools` receives the current graph `state` and returns a string or a list of strings indicating which node or nodes to call next.\n",
        "This is done by checking the tool_calls in the chatbot's output.\n",
        "Again this will will be replaced by a prebuilt `tools_condition` function later.\n",
        "\n",
        "After that, we add the function to the graph using `add_conditional_edges`\n",
        "\n",
        "Finally, we add tools-chatbot and start-chatbot edges to the graph\n",
        "\n",
        "it's to be noticed guys that as the condition can return `__end__`, we don't need to explicitly set a finish_point this time. Our graph already has a way to finish!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz9uNToNoqYd"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "\n",
        "def route_tools(\n",
        "    state: State,\n",
        ") -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return \"__end__\"\n",
        "\n",
        "\n",
        "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n",
        "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "    # It defaults to the identity function, but if you\n",
        "    # want to use a node named something else apart from \"tools\",\n",
        "    # You can update the value of the dictionary to something else\n",
        "    # e.g., \"tools\": \"my_tools\"\n",
        "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgkWOOaLoqYd"
      },
      "source": [
        "Let's visualize the graph we've built now using the `get_graph` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d-tvNkaoqYd",
        "outputId": "4181dde7-62b4-46c9-d995-59cac9784c83"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "driCSKfhoqYd"
      },
      "source": [
        "Now we can ask the bot questions outside its training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABoFtsHpoqYe",
        "outputId": "8a2a44d2-98e7-46a0-8ba6-ba78456bc600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: \n",
            "Assistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph - LangChain ... LangGraph\"}, {\"url\": \"https://blog.langchain.dev/langgraph-cloud/\", \"content\": \"Announcing LangGraph v0.1 & LangGraph Cloud: Running ...\"}]\n",
            "Assistant: LangGraph appears to be associated with LangChain, a company focused on developing tools and infrastructure for working with language models. Here are some insights based on the search results:\n",
            "\n",
            "1. **LangGraph**: It is likely a product or service offered by LangChain. The specifics about what LangGraph does weren't detailed in the search snippets, but it could involve tools or frameworks for working with language models.\n",
            "\n",
            "2. **LangGraph Cloud**: This seems to be a cloud-based offering, possibly a platform to run and manage language models or related applications more efficiently.\n",
            "\n",
            "To get more detailed information, you can visit:\n",
            "- [LangGraph on LangChain's website](https://www.langchain.com/langgraph)\n",
            "- [Announcement of LangGraph v0.1 & LangGraph Cloud](https://blog.langchain.dev/langgraph-cloud/)\n",
            "Assistant: Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
        "        for value in event.values():\n",
        "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
        "                print(\"Assistant:\", value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SekmelDgoqYe"
      },
      "source": [
        "# Congratulations\n",
        "\n",
        "Congrats guys! You've created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this LangSmith trace. Let me know if you need a video on this.\n",
        "\n",
        "Now the problem here is that our chatbot still can't remember past interactions on its own, limiting its ability to have coherent, multi-turn conversations. In the next part, we'll add memory to address this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzRcXvVEoqYe"
      },
      "source": [
        "# Sources\n",
        "https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mistral_n",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}