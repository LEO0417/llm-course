{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WeHOLpNAzLWZ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai python-dotenv markdownify  -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain Models\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# Standard Helpers\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Text Helpers\n",
        "from bs4 import BeautifulSoup\n",
        "from markdownify import markdownify as md\n",
        "\n",
        "# For token counting\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "def printOutput(output):\n",
        "    print(json.dumps(output,sort_keys=True, indent=3))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "SJ1H0ZhlzWH-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It's better to do this an environment variable but putting it in plain text for clarity\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\", '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')"
      ],
      "metadata": {
        "id": "rxMfRclTzlGu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo-0613\", # Cheaper but less reliable\n",
        "    temperature=0,\n",
        "    max_tokens=2000,\n",
        "    openai_api_key=openai_api_key\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL3gp_UD06KQ",
        "outputId": "2895b368-a7bb-4d65-d97d-b25a1261c8fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling Hello World Example\n",
        "Create an object that holds information about the fields you'd like to extract"
      ],
      "metadata": {
        "id": "HS5RSMA62LW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_food_mentioned\",\n",
        "        \"description\": \"Get the food that is mentioned in the review from the customer\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"food\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The type of food mentioned, ex: Ice cream\"\n",
        "                },\n",
        "                \"good_or_bad\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"whether or not the user thought the food was good or bad\",\n",
        "                    \"enum\": [\"good\", \"bad\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"location\"]\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "VebekkIj2MZ5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chat(messages=\n",
        "     [\n",
        "         SystemMessage(content=\"You are an helpful AI bot\"),\n",
        "         HumanMessage(content=\"I thought the burgers were awesome\")\n",
        "     ],\n",
        "     functions=functions\n",
        ")\n",
        "\n",
        "print(json.dumps(output.additional_kwargs, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVDXPiOc2V8y",
        "outputId": "75c02bf8-e142-4850-986e-a3242cabd10a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"function_call\": {\n",
            "        \"arguments\": \"{\\n  \\\"food\\\": \\\"burgers\\\",\\n  \\\"good_or_bad\\\": \\\"good\\\"\\n}\",\n",
            "        \"name\": \"get_food_mentioned\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pydantic Model\n",
        "Now let's do the same thing but with a pydantic model rather than json schema"
      ],
      "metadata": {
        "id": "A3USqnpE30Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "import enum\n",
        "\n",
        "class GoodOrBad(str, enum.Enum):\n",
        "    GOOD = \"Good\"\n",
        "    BAD = \"Bad\"\n",
        "\n",
        "class Food(BaseModel):\n",
        "    \"\"\"Identifying information about a person's food review.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"Name of the food mentioned\")\n",
        "    good_or_bad: GoodOrBad = Field(..., description=\"Whether or not the user thought the food was good or bad\")"
      ],
      "metadata": {
        "id": "1BL2XNRX2eub"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chat(messages=\n",
        "     [\n",
        "         SystemMessage(content=\"You are an helpful AI bot\"),\n",
        "         HumanMessage(content=\"I thought the burgers were awesome\")\n",
        "     ],\n",
        "     functions=[{\n",
        "         \"name\": \"FoodExtractor\",\n",
        "         \"description\": (\n",
        "             \"Identifying information about a person's food review.\"\n",
        "         ),\n",
        "         \"parameters\": Food.schema(),\n",
        "        }\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "IC6BBkLN7vmP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhH_USoe8xKl",
        "outputId": "7ad3e39d-3b17-4fb9-f152-6ac356cda858"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"name\": \"burgers\",\\n  \"good_or_bad\": \"Good\"\\n}', 'name': 'FoodExtractor'}})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But LangChain has an abstraction for us that we can use"
      ],
      "metadata": {
        "id": "kfCXpgYO8531"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "\n",
        "# Extraction\n",
        "chain = create_extraction_chain_pydantic(pydantic_schema=Food, llm=chat)\n",
        "\n",
        "# Run\n",
        "text = \"\"\"I like burgers they are great\"\"\"\n",
        "chain.run(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9t3yyqK8xj4",
        "outputId": "ab463ce0-78ca-470b-b6f7-aaea81a5b2f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Food(name='burgers', good_or_bad=<GoodOrBad.GOOD: 'Good'>)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Results\n",
        "Let's try to extract multiple objects from the same text. I'll create a person object now"
      ],
      "metadata": {
        "id": "1RS53ICG9VZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-4-0613\", # Cheaper but less reliable\n",
        "    temperature=0,\n",
        "    max_tokens=2000,\n",
        "    openai_api_key=openai_api_key\n",
        ")\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Someone who gives their review on different foods\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"Name of the person\")\n",
        "    foods: Sequence[Food] = Field(..., description=\"A food that a person mentioned\")"
      ],
      "metadata": {
        "id": "AecZI4C688yy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction\n",
        "chain = create_extraction_chain_pydantic(pydantic_schema=Person, llm=chat)\n",
        "\n",
        "# Run\n",
        "text = \"\"\"amy likes burgers and fries but doesn't like salads\"\"\"\n",
        "output = chain.run(text)"
      ],
      "metadata": {
        "id": "0N11J-Ho9rSv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoVWF-We9wl0",
        "outputId": "b7b64d96-e0e2-4f3f-87d2-835358381d21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Person(name='amy', foods=[Food(name='burgers', good_or_bad=<GoodOrBad.GOOD: 'Good'>), Food(name='fries', good_or_bad=<GoodOrBad.GOOD: 'Good'>), Food(name='salads', good_or_bad=<GoodOrBad.BAD: 'Bad'>)])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Query Extraction\n",
        "\n",
        "Let's do another fun example where we want to extract/convert a query from a user"
      ],
      "metadata": {
        "id": "4PuTe8UnBaG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Query(BaseModel):\n",
        "    \"\"\"Extract the change a user would like to make to a financial forecast\"\"\"\n",
        "\n",
        "    entity: str = Field(..., description=\"Name of the category or account a person would like to change\")\n",
        "    amount: int = Field(..., description=\"Amount they would like to change it by\")\n",
        "    year: int = Field(..., description=\"The year they would like the change to\")"
      ],
      "metadata": {
        "id": "Vk2I17Tf9w-Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain_pydantic(pydantic_schema=Query, llm=chat)\n",
        "\n",
        "chain.run(\"Can you please add 10 more units to inventory in 2022?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-d593xPCqVs",
        "outputId": "c5765729-4b9d-41bf-e0ab-e8570c844c43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Query(entity='inventory', amount=10, year=2022)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"Remove 3 million from revenue in 2021\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3GxNVbsC2gk",
        "outputId": "54fea569-f2df-4fb1-b4cd-b5212ceff935"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Query(entity='revenue', amount=-3, year=2021)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opening Attributes - Real World Example\n"
      ],
      "metadata": {
        "id": "m06sI5d9C9V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_from_greenhouse(board_token):\n",
        "    # If doing this in production, make sure you do retries and backoffs\n",
        "\n",
        "    # Get your URL ready to accept a parameter\n",
        "    url = f'https://boards-api.greenhouse.io/v1/boards/{board_token}/jobs?content=true'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "    except:\n",
        "        # In case it doesn't work\n",
        "        print (\"Whoops, error\")\n",
        "        return\n",
        "\n",
        "    status_code = response.status_code\n",
        "\n",
        "    jobs = response.json()['jobs']\n",
        "\n",
        "    print (f\"{board_token}: {status_code}, Found {len(jobs)} jobs\")\n",
        "\n",
        "    return jobs"
      ],
      "metadata": {
        "id": "lfyo4SinC28J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jobs = pull_from_greenhouse(\"okta\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrvVjpgjDAsy",
        "outputId": "1246f3ec-503a-46f9-8b25-4c7d78a7c22b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "okta: 200, Found 178 jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_index = 0\n",
        "print (\"Preview:\\n\")\n",
        "print (json.dumps(jobs[job_index])[:400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nepkNdP6EXD_",
        "outputId": "5394e34e-b2eb-4c16-cd20-3d16a82c60fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preview:\n",
            "\n",
            "{\"absolute_url\": \"https://www.okta.com/company/careers/opportunity/5578093?gh_jid=5578093\", \"data_compliance\": [{\"type\": \"gdpr\", \"requires_consent\": false, \"requires_processing_consent\": false, \"requires_retention_consent\": false, \"retention_period\": null}], \"internal_job_id\": 2747338, \"location\": {\"name\": \"Spain\"}, \"metadata\": null, \"id\": 5578093, \"updated_at\": \"2024-01-16T09:21:28-05:00\", \"requi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I parsed through an output to create the function below\n",
        "def describeJob(job_description):\n",
        "    print(f\"Job ID: {job_description['id']}\")\n",
        "    print(f\"Link: {job_description['absolute_url']}\")\n",
        "    print(f\"Updated At: {datetime.fromisoformat(job_description['updated_at']).strftime('%B %-d, %Y')}\")\n",
        "    print(f\"Title: {job_description['title']}\\n\")\n",
        "    print(f\"Content:\\n{job_description['content'][:550]}\")"
      ],
      "metadata": {
        "id": "o23J2AoKEd0I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a Kor object that will look for tools. This is the meat and potatoes of the application"
      ],
      "metadata": {
        "id": "81F1nYO3Yp8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tool(BaseModel):\n",
        "    \"\"\"The name of a tool or company\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"Name of the food mentioned\")\n",
        "\n",
        "class Tools(BaseModel):\n",
        "    \"\"\"A tool, application, or other company that is listed in a job description.\"\"\"\n",
        "\n",
        "    tools: Sequence[Tool] = Field(..., description=\"\"\" A tool or technology listed\n",
        "        Examples:\n",
        "        * \"Experience in working with Netsuite, or Looker a plus.\" > NetSuite, Looker\n",
        "        * \"Experience with Microsoft Excel\" > Microsoft Excel\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "PcOXt-lEYqW1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_extraction_chain_pydantic(pydantic_schema=Tools, llm=chat)"
      ],
      "metadata": {
        "id": "ZO1uDJ8YZYNg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chain(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdpt-cJKZtO9",
        "outputId": "b73034ec-ff29-4e2c-b3cf-abf4b29b1e10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    result = chain(text)\n",
        "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
        "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
      ],
      "metadata": {
        "id": "ubpBa_QoZyVV",
        "outputId": "8eb5d861-25f6-40a5-d79c-17bf7c023e11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 151\n",
            "Prompt Tokens: 133\n",
            "Completion Tokens: 18\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00507\n"
          ]
        }
      ]
    }
  ]
}